# Margin-based-Adaboost
Vanilla Adaboost implementation and Adaboost with Margin

Reference Papers: 
1) [Efficient Margin Maximizing with Boosting](http://www.jmlr.org/papers/volume6/ratsch05a/ratsch05a.pdf)
2) [How Boosting the Margin Can Also Boost Classifier Complexity](http://rob.schapire.net/papers/boost_complexity.pdf)

The Adaboost $$\rho$$ algorithm is the exact same algorithm when $$\rho = 0$$.

Pseudocode:
![Algorithm](https://github.com/deshanadesai/Margin-based-Adaboost/raw/master/images/algo.png)
